{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "boston_housing.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZN9xElULvkh",
        "colab_type": "code",
        "outputId": "05e89aef-05df-452f-bfa0-1f1b30ac90e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# predicting house prices - REGRESSION using boston housing dataset using deep learning network\n",
        "# loading the Boston housing dataset\n",
        "from keras.datasets import boston_housing\n",
        "(train_data,train_targets),(test_data,test_targets)=boston_housing.load_data()\n",
        "# get insight about the training data\n",
        "print(\"train data shape\",train_data.shape)\n",
        "print(\"test data shape:\",test_data.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 2us/step\n",
            "train data shape (404, 13)\n",
            "test data shape: (102, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYOF0_7BMDVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preparing the data , normalizing the data\n",
        "mean=train_data.mean(axis=0)\n",
        "train_data_norm=train_data-mean\n",
        "std=train_data.std(axis=0)\n",
        "train_data_norm/=std\n",
        "test_data-=mean  # normalizing test data with the same values as train data\n",
        "test_data/=std\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4APuPquRPrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building the network\n",
        "from keras import models\n",
        "from keras import layers\n",
        "def create_network():\n",
        "  model=models.Sequential()\n",
        "  model.add(layers.Dense(64, activation='relu',input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r1_UcjyU5Ok",
        "colab_type": "code",
        "outputId": "eeabe180-349a-4832-c611-440031f02a1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# k-fold validation\n",
        "import numpy as np\n",
        "k=4\n",
        "num_val_samples=len(train_data)//k\n",
        "num_val_samples\n",
        "num_epochs=100\n",
        "all_scores=[]\n",
        "for i in range(k):\n",
        "  print(\"processing fold #\",i)\n",
        "  val_data=train_data_norm[i*num_val_samples:(i+1)*num_val_samples]\n",
        "  val_targets=train_targets[i*num_val_samples:(i+1)*num_val_samples]\n",
        "  partial_train_data=np.concatenate([train_data_norm[:i*num_val_samples],train_data_norm[(i+1)*num_val_samples:]],axis=0)\n",
        "  partial_train_targets=np.concatenate([train_targets[:i*num_val_samples],train_targets[(i+1)*num_val_samples:]],axis=0)\n",
        "  model=create_network()\n",
        "  model.fit(partial_train_data,partial_train_targets,epochs=num_epochs,batch_size=1,verbose=0)\n",
        "  val_mse,val_mae=model.evaluate(val_data,val_targets,verbose=0)\n",
        "  all_scores.append(val_mae)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGZZKx2RZllM",
        "colab_type": "code",
        "outputId": "9b5892db-ae80-4be7-901c-13bebcb0bf96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"all scores\",all_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all scores [1.8179170259154669, 2.3360615838872323, 2.6472588447060916, 2.3052040905055433]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCFa4kQs0VAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}